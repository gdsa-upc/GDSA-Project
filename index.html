<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Terrassa’s Buildings by gdsa-upc</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Terrassa’s Buildings</h1>
      <h2 class="project-tagline">Projecte GDSA</h2>
      <a href="https://github.com/gdsa-upc/Terrassa-s-Buildings" class="btn">View on GitHub</a>
      <a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/gh-pages/images/Logo.png?raw=true" alt=""></p>

<p>Aquesta web neix a partir de l'assignatura Gestió i Distribució de Senyals Audiovisuals, on es planteja el desenvolupament d'un projecte que es basa en la cerca visual. Aquest projecte l'hem donat com a nom Terrassa's Buildings i els seus desenvolupadors són:</p>

<table>
<thead>
<tr>
<th>Nom i Cognom</th>
<th>Perfil Github</th>
<th>Perfil de LinkedIn</th>
</tr>
</thead>
<tbody>
<tr>
<td>Marta Barrachina</td>
<td><a href="https://github.com/Mmarta19">Enllaç</a></td>
<td><a href="https://es.linkedin.com/in/marta-barrachina-234697117">Enllaç</a></td>
</tr>
<tr>
<td>Marta Coll</td>
<td><a href="https://github.com/MartaCollPol">Enllaç</a></td>
<td></td>
</tr>
<tr>
<td>David Molina</td>
<td><a href="https://github.com/Damocle21">Enllaç</a></td>
<td></td>
</tr>
</tbody>
</table>

<p>En concret Terrassa's Buildings és una plataforma que està implementada i desenvolupada amb el llenguatge Python. Per entendre millor el projecta, s'ha dividit aquest en sessions. En cada una de les sessions s'explica en detall els passos que s'han portat a terme per obtenir l'objectiu final.</p>

<table>
<thead>
<tr>
<th>Sessions</th>
<th>LINK</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sessió 3</td>
<td><a href="https://docs.google.com/presentation/d/10qN_5L64CRrDN-KxAChikhTSHKhgo5Zdgb-cuL4wFAA/edit?usp=sharing">Extreure característiques</a></td>
</tr>
<tr>
<td>Sessió 4</td>
<td><a href="https://docs.google.com/presentation/d/1BYy3HgLG6q_1lNq15vN7Gp8xHzMo9Y2DdIURvjgpsQ4/edit?usp=sharing">Primer prototipus de cercador</a></td>
</tr>
<tr>
<td>Sessió 5</td>
<td><a href="https://docs.google.com/presentation/d/1WQZ6u9ZcucOMAc_W2__FvCq-HeTcyD7znJaK6clQooo/edit?usp=sharing">Improvements on the baseline</a></td>
</tr>
</tbody>
</table>

<h1>
<a id="sessió-3" class="anchor" href="#sessi%C3%B3-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://docs.google.com/presentation/d/10qN_5L64CRrDN-KxAChikhTSHKhgo5Zdgb-cuL4wFAA/edit?usp=sharing">Sessió 3</a>
</h1>

<p>En aquesta primera part del projecte s'ha realitzat una <a href="https://drive.google.com/file/d/0BwPBlegi0csQamhIU3YyT1o3ZGs/view?usp=sharing">Base de Dades</a> amb 150 imatges diferents. Majoritàriament trobem imatges del Museu de la Ciència i la Tecnologia de Terrassa, del Mercat de la Independència. Encara així, en la base de dades també hi han imatges d'edificis desconeguts. Totes aquestes fotografies serviran d'entrenament al sistema. </p>

<table>
<thead>
<tr>
<th><a href="http://mnactec.cat/ca/">MNACTEC</a></th>
<th><a href="http://www.mercatdelaindependencia.cat/?doing_wp_cron=1479940928.3758389949798583984375">Mercat de la Independència</a></th>
<th>Desconegut</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/gh-pages/images/1354-30624-16524.jpg?raw=true" alt=""></td>
<td><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/gh-pages/images/3311-27747-29929.jpg?raw=true" alt=""></td>
<td><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/gh-pages/images/Desconegut_102.jpg?raw=true" alt=""></td>
</tr>
</tbody>
</table>

<p>El sistema també farà servir 450 fotografies de diferents edificis de Terrassa, on la seva utilitat és de validació que serviran per evaluar el sistema. Aquestes imatges es poden trobar a la pàgina web del UPC <a href="https://imatge.upc.edu/web/resources/terrassa-buildings-900">Terrassa Building 900</a>.</p>

<p>Un cop hem obtingut totes les imatges, és important fer una anotació d'aquestes per generar correctament la base de dades. El sistema d'anotació que s'ha utilitzat en aquest projecte és el següent:</p>

<p><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/gh-pages/images/Captura%20de%20pantalla%202016-11-27%20a%20les%2011.31.12.png?raw=true" alt=""></p>

<p>Totes aquestes imatges s'han guardat en un arxiu <a href="https://drive.google.com/file/d/0BwPBlegi0csQamhIU3YyT1o3ZGs/view?usp=sharing">ZIP</a>.</p>

<p>Pel desenvolupament del projecta s'ha fet servir dos entorns de desenvolupament local.</p>

<ul>
<li><p><a href="https://www.enthought.com/products/canopy/">Canopy</a>: Entorn d'anàlisi de Python integral que proporciona més de 450 paquets de Python.</p></li>
<li><p><a href="https://atom.io">Atom</a>: Editor de text de software lliure en el que es pot treballar còmodament amb diferents idiomes de programació. Disposa de molts paquets descarregables que amplien les seves funcions com ara compiladors o personalitzadors. </p></li>
</ul>

<p>Amb aquestes dos entorns s'ha genera el primer script. Aquest es basa en l'extracció de punts d'interès d'una imatges. S'ha fet de dos extractors de característiques diferents, SURF, SIFT i ORB. A continuació podeu veure els codis realitzats agafant d'exemple, en els dos primers casos (SURF i SIFT), una imatge d'un tigre. En el cas d'ORB es fa servir una imatge de la nostre base de dades.</p>

<ul>
<li>
<p><a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/1--Keypoints/PuntsInteres_SURF.ipynb">SURFT</a></p>

<p><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/1--Keypoints/figure_1.png?raw=true" alt=""></p>
</li>
</ul>

<p>Utilitzant SURFT podem observar que ens detalla els contorns més pronunciats de la imatge.</p>

<ul>
<li><a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/1--Keypoints/PuntsInteresSIFT.ipynb">SIFT</a></li>
</ul>

<p><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/1--Keypoints/Imagen%201.png?raw=true" alt=""></p>

<p>En aquest cas com veiem a la imatge anterior, el resultat de l'extracció de característiques és més detallat. Sobretot en els canvis d'intensitat, és a dir, en els contorns.</p>

<ul>
<li><a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/1--Keypoints/PuntsDInteresORB.ipynb">ORB</a></li>
</ul>

<p><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/Marta-C/Mercat.png?raw=true" alt=""></p>

<p>Observem de color vermell els punts d'interés que s'han trobat a la imatge que corresponen sobretot a contorns o zones amb variacions ràpides de color(com les lletres del cartell). En aquest cas, ens podem fixar que en un dels contorns de la imatge tenim un marca generada per la funda del telèfon amb el qual s'estava capturant la imatge. Això pot ser un cas real i és per aquest motiu que ho hem volgut fer servir.</p>

<p>Les proves d'aquest primer script també s'han realitzat a <a href="http://jupyter.org">Jupyter</a>. Podeu veure tot el codi realitzat a <a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/tree/master/1--Keypoints">GitHub</a>.</p>

<h1>
<a id="sessió-4" class="anchor" href="#sessi%C3%B3-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://docs.google.com/presentation/d/1BYy3HgLG6q_1lNq15vN7Gp8xHzMo9Y2DdIURvjgpsQ4/edit?usp=sharing">Sessió 4</a>
</h1>

<p>Aquesta sessió està formada pels següents blocs:</p>

<p><img src="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/gh-pages/images/Captura%20de%20pantalla%202016-11-29%20a%20les%2022.03.21.png?raw=true" alt=""></p>

<p>1-<a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/1-Build_Database/build_database.py">Build_Database</a>
Generar una base de dades. Ho hem implementat utilitzant la funció build_database.</p>

<p>2- FEATURE_EXTRACTION
Formada per les següents funcions:</p>

<ul>
<li><p><a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/2--Get_Features/get_params.py">get_params</a>
Utilitzarem aquesta funció per a definir tots els peràmetres que farem servir en les pròximes funcions amb la idea de tenir un codi més ordenat. Definirem aqui des del path cap a la base de dades fins a la mida de descriptor, mida d’imatges, etc.</p></li>
<li><p>image_local_features
Obtenim els descriptors amb la funció local_feature_extraction(params, image).
Primer s’extreuen utilitzant el tipus de descriptor ORB pels casos en que la imatge que es llegeix de la llibreria és .jpg o .JPG, ja que, de no fer-ho obtenim un error Nontype. A continuació,  la funció resize que apliquem a les imatges per a fer-les més petites amb la idea de no saturar la memoria al compilar.</p></li>
</ul>

<div class="highlight highlight-source-python"><pre><span class="pl-k">def</span> <span class="pl-en">image_local_features</span>(<span class="pl-smi">image</span>):
    <span class="pl-c">#llegim la imatge:</span>
    <span class="pl-c">#img = cv2.imread(image)</span>
    <span class="pl-c">#Cambiem la mida de la imatge:</span>
    <span class="pl-k">if</span> <span class="pl-k">not</span> image <span class="pl-k">is</span> <span class="pl-c1">None</span>:

        <span class="pl-c">#linea que soluciona un bug de opencv a python3</span>
        <span class="pl-c">#cv2.ocl.setUseOpenCL(False)</span>

        <span class="pl-c"># Creem l'objecte ORB que tindrà 200k keypoints. (Perametre que podem modificar per no saturar el programa)</span>
        orb <span class="pl-k">=</span> cv2.ORB(<span class="pl-c1">200000</span>)

        <span class="pl-c"># Detectem els keypoints:</span>
        kp <span class="pl-k">=</span> orb.detect(image,<span class="pl-c1">None</span>)

        <span class="pl-c"># Calculem els descriptors amb els keypoints trobats.</span>
        kp, des <span class="pl-k">=</span> orb.compute(image, kp)

        <span class="pl-c"># la sortida de la funció serà els descriptors</span>
        <span class="pl-k">return</span> des</pre></div>

<ul>
<li>train_codebook
Per definir aquesta funció fem servir MiniBatchKMeans. Això és així ja que, és molt més ràpid que altres aplicacions per defecte. Ens cal limitar el nombre de features o d’imatges. </li>
</ul>

<div class="highlight highlight-source-python"><pre><span class="pl-k">def</span> <span class="pl-en">train_codebook</span>(<span class="pl-smi">params</span>,<span class="pl-smi">X</span>):

    <span class="pl-c"># Init kmeans instance</span>
    km <span class="pl-k">=</span> MiniBatchKMeans(params[<span class="pl-s"><span class="pl-pds">'</span>descriptor_size<span class="pl-pds">'</span></span>])

    <span class="pl-c"># Training the model with our descriptors</span>
    km.fit(<span class="pl-c1">X</span>)

    <span class="pl-c"># Save to disk</span>
    pickle.dump(km,<span class="pl-c1">open</span>(os.path.join(params[<span class="pl-s"><span class="pl-pds">'</span>root<span class="pl-pds">'</span></span>],params[<span class="pl-s"><span class="pl-pds">'</span>root_save<span class="pl-pds">'</span></span>],
                                     params[<span class="pl-s"><span class="pl-pds">'</span>codebooks_dir<span class="pl-pds">'</span></span>],<span class="pl-s"><span class="pl-pds">'</span>codebook_<span class="pl-pds">'</span></span>
                                     <span class="pl-k">+</span> <span class="pl-c1">str</span>(params[<span class="pl-s"><span class="pl-pds">'</span>descriptor_size<span class="pl-pds">'</span></span>]) <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span>_<span class="pl-pds">"</span></span>
                                     <span class="pl-k">+</span> params[<span class="pl-s"><span class="pl-pds">'</span>descriptor_type<span class="pl-pds">'</span></span>]
                                     <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span>_<span class="pl-pds">"</span></span> <span class="pl-k">+</span> params[<span class="pl-s"><span class="pl-pds">'</span>keypoint_type<span class="pl-pds">'</span></span>] <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">'</span>.cb<span class="pl-pds">'</span></span>),<span class="pl-s"><span class="pl-pds">'</span>wb<span class="pl-pds">'</span></span>))

    <span class="pl-k">return</span> km</pre></div>

<ul>
<li>get_assignments
Aquesta funció calcula les assignacións i es retorna un vector:  per cada descriptor quantes assignacions té. </li>
</ul>

<div class="highlight highlight-source-python"><pre><span class="pl-k">def</span> <span class="pl-en">get_assignments</span>(<span class="pl-smi">km</span>,<span class="pl-smi">descriptors</span>):

    assignments <span class="pl-k">=</span> km.predict(descriptors)

    <span class="pl-k">return</span> assignments</pre></div>

<ul>
<li>Bow
Aquesta funció crea un descriptor del mateix tamany que el número de clusters tot a zeros. Per cada entrada a l’assigment, es suma 1 al índex que toca a l’histograma. Per finalitzar, el normalitzem amb L2. </li>
</ul>

<div class="highlight highlight-source-python"><pre><span class="pl-k">def</span> <span class="pl-en">bow</span>(<span class="pl-smi">assignments</span>,<span class="pl-smi">km</span>):

    <span class="pl-c"># Initialize empty descriptor of the same length as the number of clusters</span>
    descriptor <span class="pl-k">=</span> np.zeros(np.shape(km.cluster_centers_)[<span class="pl-c1">0</span>])

    <span class="pl-c"># Build vector of repetitions</span>
    <span class="pl-k">for</span> a <span class="pl-k">in</span> assignments:

        descriptor[a] <span class="pl-k">+=</span> <span class="pl-c1">1</span>

    <span class="pl-c"># L2 normalize</span>
    descriptor <span class="pl-k">=</span> normalize(descriptor)

    <span class="pl-k">return</span> descriptor</pre></div>

<ul>
<li>
<a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/2--Get_Features/get_features.py">Get_features</a>
Aquesta es la funció general, s’obra el fitxer on tenim els Id de les imatges d’entrenament/validació, s’extreuen les característiques i es crea el ‘Diccionari’, on i guardarem els descriptors per a cada imatge. Per últim, es guarda el diccionari a Features. </li>
</ul>

<p>3- <a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/3--Ranking/rank.py">RANKING</a></p>

<p>L'objectiu de la funció Rank és la creació i ordenació del rànquing per a cada imatge de validació.</p>

<p>4-<a href="https://github.com/gdsa-upc/Terrassa-s-Buildings/blob/master/4--Evaulate-ranking/eval_rankings.py">EVALUATE_RANKING</a></p>

<p>Finalment evaluete_ranking està formada per diferents funcions:</p>

<ul>
<li><p>Display: En aquesta part es llegeix les imatges de la base de dades i es posa contorns blaus per la consulta. Més tard només mostrem els primers 15 elements del ranking. On els llegim i comparem. Si són semblants, posem el contorn verd i si són diferents, posem el contorn de color vermell.</p></li>
<li><p>Read_annotation(): Llegim les anotacions del directori train i val.</p></li>
<li><p>Get_hitandmiss: Inicilitzem la llista de salts o encerts. Per cada id de les imatges del ranking, obtenim la classe de l'anotació d'entrenament. En el cas que coincideixi amb la classe de consulta, aleshores això vol dir que és correcta. En el cas contrari, vol dir que és fals.</p></li>
<li><p>AveragePrecision: En aquesta funció inicialitzem les variables accu (suma de precisions) i numRel (número de instants correctes). Aleshores omplim aquestes variable amb un for per tots els elements de la llista de salts o encerts. Un cop s'ha llegit tots els elements de la llista, es fa la següent divisió:</p></li>
</ul>

<div class="highlight highlight-source-python"><pre><span class="pl-k">return</span> (accu<span class="pl-k">/</span>np.sum(relist))</pre></div>

<ul>
<li><p>Load_ranking: Carga i retorna el ranking del txt. També retorna la classe de la imatge de consulta</p></li>
<li><p>Save_ranking_file: En la següent funció escriu el nom de consulta. Més tard passa els elements string i ranking a llista.</p></li>
<li><p>Eval_rankings: Per tots els rankings generats, obté la llista de salts o encerts i calcula la mitjana de precisió de la llista.</p></li>
<li><p>Single_eval: Finalment en aquesta part mostrem per pantalla els diferents càlculs que s'han anat fent.</p></li>
</ul>

<h1>
<a id="sessió-5" class="anchor" href="#sessi%C3%B3-5" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://docs.google.com/presentation/d/1WQZ6u9ZcucOMAc_W2__FvCq-HeTcyD7znJaK6clQooo/edit?usp=sharing">Sessió 5</a>
</h1>

<p>En aquesta sessió del projecte, la intenció és finalitzar les funcions feature_extraction, ranking i evaluation. Però la part més important de la sessió és la Improvements on the baseline. </p>

<p>La millora que hem fet ho hem aconseguit mitjançant la combinació de SIFT i ORB. Primer de tot hem definit la funció Sift_features() dintre de get_features:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">def</span> <span class="pl-en">sift_features</span>(<span class="pl-smi">image</span>):
    <span class="pl-k">if</span> <span class="pl-k">not</span> image <span class="pl-k">is</span> <span class="pl-c1">None</span>:
        <span class="pl-c">#Extract sift descriptors</span>
        sift <span class="pl-k">=</span> cv2.SIFT(<span class="pl-c1">200000</span>)
        kp_sift <span class="pl-k">=</span> sift.detect(image,<span class="pl-c1">None</span>)
        kp_sift, des_sift <span class="pl-k">=</span> sift.compute(image, kp_sift)
        <span class="pl-c">#print len(kp_sift)</span>
        <span class="pl-c">#print len(des_sift)</span>
        <span class="pl-k">return</span> des_sift</pre></div>

<p>I dintre de image_local_features(image) hem aplicat ORB.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">def</span> <span class="pl-en">image_local_features</span>(<span class="pl-smi">image</span>):
    <span class="pl-c">#llegim la imatge:</span>
    <span class="pl-c">#img = cv2.imread(image)</span>
    <span class="pl-c">#Cambiem la mida de la imatge:</span>
    <span class="pl-k">if</span> <span class="pl-k">not</span> image <span class="pl-k">is</span> <span class="pl-c1">None</span>:

        <span class="pl-c">#linea que soluciona un bug de opencv a python3</span>
        <span class="pl-c">#cv2.ocl.setUseOpenCL(False)</span>

        <span class="pl-c"># Creem l'objecte ORB que tindrà 200k keypoints. (Perametre que podem modificar per no saturar el programa)</span>
        orb <span class="pl-k">=</span> cv2.ORB(<span class="pl-c1">200000</span>)

        <span class="pl-c"># Detectem els keypoints:</span>
        kp_o <span class="pl-k">=</span> orb.detect(image,<span class="pl-c1">None</span>)

        <span class="pl-c"># Calculem els descriptors amb els keypoints trobats.</span>
        kp, des<span class="pl-k">=</span> orb.compute(image, kp_o)

        <span class="pl-k">return</span> des</pre></div>

<p>A continuació podeu veure el resultat. <a href="https://docs.google.com/presentation/d/1WQZ6u9ZcucOMAc_W2__FvCq-HeTcyD7znJaK6clQooo/edit?usp=sharing">Enllaç</a></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/gdsa-upc/Terrassa-s-Buildings">Terrassa’s Buildings</a> is maintained by <a href="https://github.com/gdsa-upc">gdsa-upc</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
